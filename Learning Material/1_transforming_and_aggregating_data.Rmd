---
title: "Transforming and Aggregating Data"
author: "Adnan Shroufi"
date: "2025-02-06"
output: html_document
---

```{r setup, echo=TRUE, eval=TRUE}
if (!requireNamespace("rprojroot", quietly = TRUE)) {install.packages("rprojroot")}
knitr::opts_knit$set(root.dir = rprojroot::find_root(criterion = rprojroot::is_rstudio_project))
```

# Introduction

In the previous markdown file we had a first look at our monthly and regional anti-depressant prescribing data.
We can load it now and quickly check again it's structure how many rows it had.

```{r}
data = readRDS("Data/STEP_UP_REGIONAL_ANTIDEPRESSANTS.Rds")
str(data)
nrow(data)
```

So this data has over 9k rows, so is fairly big.
To make sense of this, it can help if we *aggregate* or *summarise* the data.

For example, we know there are lots of different anti-depressants being prescribed in a region.
But what about if we wanted to know how many items in total were being prescribed in a region?

We need to cover a few things first, before moving onto that. Those things are:

- how to install a package

## Installing and Loading a Package

Before we do that, we need to learn how to install and load an R 'package'.
A package is basically a collection of functions.
While Base R has some functions, if we want more functions we have to install additional packages.

We will install a package now using the *install.packages* function.
The package we will install is called *dplyr*.
This is probably the most important packages we will use in the Step-up Challenge.

We will explain what the *dplyr* package does in the next section.
The package name must be in (either single or double) quotation marks. 

```{r}
install.packages("dplyr")
```

We then need to load the functions from this package, so we can use them.
If you close down your session and start again later, you would need to re-load the package again.
We load a package using the *library* function.

```{r}
library(dplyr)
```

## Tidy Programming

The *dplyr* package is the foundation of *tidy* programming R.
It has a suite of function to make data transformation in R a lot easier, than i you were using Base R. 

Tidy programming (with dplyr), is a little different to Base R, and has various benefits:

- It is easy to read and write
- The functions work in similar and predictable ways
- We can use a *pipe* (%>%) to create sequential workflows

Here is a cheat sheet for the most important dplyr functions.
You can do a huge amount of data transformation just using the functions in this package. 

```{r}
browseURL("https://rstudio.github.io/cheatsheets/data-transformation.pdf")
```

Using the pipe command (%>%) we can 'chain' various functions together.
This is rather than wrapping functions around each other, or writing lots of individual lines of code.

## Basic Data Transformations

The first 3 dplyr functions we will look at are *select* and *filter*.

*select()*: this function, as you might guess, selects some columns from a dataframe
*filter()*: this function, filters some rows from a dataframe, based upon a condition
*distinct()*: this function reduces a column (or series of columns) to their distinct entries

We will write some very basic dplyr code now.
After each pipe, press enter to start on a new line.
R should automatically indent the code appropriately.

We will use *select* to select a single column from our dataframe.
Now, this column must spelt *exactly* as in our dataframe, so in this instance uppercase.

```{r}
data %>% 
  select(DRUG)
```

We can now *pipe* another command after our *select*.
We will use *distinct*, which can be ran without any parameters inside the function.

```{r}
data %>% 
  select(DRUG) %>% 
  distinct()
```

We can see that there are 32 distinct drugs within our data.
We can now see what the distinct regions are.

```{r}
data %>% 
  select(REGION) %>% 
  distinct()
```

Usually, you would want to know the distinct entries for a *factor* or *character* columns.
If you *distinct* on an *integer* or *numeric* column, you will simple get every numerical value within a column (which could be a lot of different values). 
The below code isn't a particularly use case of the *distinct* function.

```{r}
data %>% 
  select(ITEMS) %>% 
  distinct()
```

Using *filter*, we can filter out some records, or focus on a partiucular set of rows, within our data.
What we need to do is specify:

- the column we want to filter
- what we want to filter it by

In the below example I want to filter the *REGION* column so we only have left records for the *NORTH WEST*.
I need to use *==* within the function, which is a logical comparison operator, that basically checks if two things are equal.

```{r}
data %>% 
  filter(REGION == "NORTH WEST")
```

The opposite to this is the *!=*, which checks if two things are *not* equal.
The below filters *not* the NORTH WEST region.
In effect, it is saying keep all rows, except the rows belonging to the NORTH WEST.

```{r}
data %>% 
  filter(REGION != "NORTH WEST")
```

It is possible to chain all the functions used so far together.
The following code would list what distinct anti-depressants were prescribed in the NORTH WEST region across the whole dataset.

```{r}
data %>% 
  filter(REGION == "NORTH WEST") %>% 
  select(DRUG) %>% 
  distinct()
```

I can also have multiple conditions within a single filter function (note the comma placement).
The following lists what distinct anti-depressants were prescribed in the NORTH WEST region, just for January 2024.
The output is slightly different to the previous one.

```{r}
data %>% 
  filter(REGION == "NORTH WEST", YM == 202401) %>% 
  select(DRUG) %>% 
  distinct()
```

## Piping Functions

As seen, we can use the pipe operator (%>%) to chain functions together.
This can make more readable, and also clearly shows the sequence in which functions are being run.

The below code does the same as above (using dplyr functions) yet without any pipe operators.
In the below code each functions 'wraps' around the next.
To interpret the below code you have to 'unpack' what is actually going on.

```{r}
distinct(select(filter(data, REGION == "NORTH WEST", YM == 202401), DRUG))
```

By contrast the sequencing of the previous code (with %>%) is more explicit:

1. Filter the data 
2. Select a single column
3. Find the distinct entries for that column

So in summary, the dplyr package is extremely useful, and the pipe operator makes both the reading and writing of dplyr code easier to do.
Rather than typing *%>%* over and over, we can use some shortcuts to make using the pipe a bit easier.
The shortcuts for windows and Mac computers are:

*Windows*: CTRL + SHIT + M
*Mac*: CMD + SHIT + M

```{r}
data %>% 
  group_by(REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup()

```

## Assigning Data

You might have noticed that nothing new has appeared in global environment pane (top right) so far.
This is because we haven't 'created' any new objects yet.
Lets say I want to create a new object call *df_filter*, which just contained data from the NORTH WEST region, I could do the following.

```{r}
df_filter = data %>% 
  filter(REGION == "NORTH WEST")
```

There is now a new object in the global environment, which has far fewer rows, due to the filter operation.
We have *assigned* the output from the filter function to a new object.
Conventionally, many (or some) people use a different way to assign a value to a new object.
They would use the following code.

```{r}
df_filter <- data %>% 
  filter(REGION == "NORTH WEST")
```

the left facincg arrow here indicates that the output from the code block is to assigned in the direction the arrow is pointing.
For the purposes of the step-up Challenge, we will just use the *=* operator to assign values (or create new objects).

## Aggregating Data

With a basic understanding of the dplyr package, how to pipe functions and assign a value to anew object, we can now *aggregate* or *summarise* data.
So far we have just loooked at distinct entries per column.
Something far more useful, might be to *sum* the total items belonging to a certain category.

We need to use 3 functions (often used together) to do this:

- group_by()
- summarise()
- ungroup()

For example, if I want to find the total number of anti-depressants prescribed per region, across the entire time frame, I would do the following:

```{r}
data %>% 
  group_by(REGION) %>% 
  summarise(ALL_ITEMS = sum(ITEMS)) %>% 
  ungroup()
```

Each line of the above code is now explained:

*1. data %>%*: this is the data we are feeding into the subsequent functions
*2. group_by(REGION) %>%*: we are sorting the data into groups, in this instance each region(7 groups)
*3. summarise(ALL_ITEMS = sum(ITEMS)) %>%*: now the data is grouped, we can add up all the items per group, and choose a name for this new column (in this instance *ALL_ITEMS*).
*4. ungroup()*: we've finished our aggregating, so need to put the data 'back to normal', rather than in groups. Note, there is no pipe here as this is the end of the code block.

We can change the grouping variable to YM (year-month) and see what the output looks like.
This time the ITEM column will not be renamed after being summed.
The number of rows in the output is the same as the number of YM categories.

```{r}
data %>% 
  group_by(YM) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup()
```

Next, we can also group by 2 variables.
If we group by REGION and YM, we are grouping the data by every combination of REGION and YM.
We will assign the output of this to a new variable so we can inspect the output.

```{r}
df_region_ym = data %>% 
  group_by(REGION, YM) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup()
```

If we click on the new object within the global environment pane we can inspect the output.
As we can see, we have the total number items, per region, per year-month. 

Within the *summarise* function, we can actually do multiple calculations.
Below is the same grouping, with the same ITEMS sum, also with a COST sum.
I am assigning the output to the same variable, meaning I will 'write over' the previous one.

```{r}
df_region_ym = data %>% 
  group_by(REGION, YM) %>% 
  summarise(ITEMS = sum(ITEMS), COST = sum(COST)) %>% 
  ungroup()
```

The final aggregation we will now do is count the number of unique anti-depressants prescribed per region per month.
We can do this using *n_distinct* within the *summarise*.
For clarity, to compare with the 'normal' *distinct* function:

- *distinct()*: to find the distinct (or unique) rows within a dataframe
- *n_distinct()*: to count the number of unique values within a column

Once again, we will assign the output to the same variable.

```{r}
df_region_ym = data %>% 
  group_by(REGION, YM) %>% 
  summarise(ITEMS = sum(ITEMS), COST = sum(COST), N_DRUGS = n_distinct(DRUG)) %>% 
  ungroup()
```

## Sorting Data

In addition to transforming (changing the shape/structure) of data, and aggregating data, another thing we might want to do is sort data.
This could be putting a column into ascending or descending order, or taking the top values from a column.

We can sort numerical values using the *arrange* function.
This time, we will only group by REGION, and only sum the ITEMS column.
We will then sort the above data by the ITEMS column.
View the object in the global environment of *arrange*.

```{r}
df_region = data %>% 
  group_by(REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup() %>% 
  arrange(ITEMS)
```

As we can see, the values are sorted from smallest to biggest.
The below code would sort from biggest to smallest (descending in value).

```{r}
df_region = data %>% 
  group_by(REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup() %>% 
  arrange(desc(ITEMS))
```

And finally, we can select the top number of rows by a given column, using *top_n*.
The below code identifies and retains the 3 regions with the greatest total item count.
We are then sorting the remaining 3 records in descending order by their ITEMS value.
The *top_n* and *arrange* functions could be run in either order and the same result would be achieved.

```{r}
df_region_top = data %>% 
  group_by(REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup() %>% 
  top_n(3, ITEMS) %>% 
  arrange(desc(ITEMS))
```

## Pivoting data

We need to install one extra package, even though we only require one function (pivot_wider) from it in this session.
It's called *tidyr* and used for data transformation and manipulation.
We will install and load it now.

```{r}
install.packages("tidyr")
library(tidyr)
```

Here is a cheatsheet if you want to see what other functions the tidyr package has. 

```{r}
browseURL("https://rstudio.github.io/cheatsheets/tidyr.pdf")
```

The final thing we will look at is how to pivot data, this help with presenting data more effectively, rather than generating new insight.
First lets use a group_by and summarise our data, to the annual sum of items per region, so group_by YEAR and REGION and sum ITEMS.

```{r}
data %>% 
  group_by(YEAR, REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup()
```

We want our data formatted like this if we want to plot our data.
However, if we want to present this as a table in a report, we would want to pivot or 'spread' the values out.
The tidyr *pivot_wider* function can do this.

We just need to specify 2 things:

- The column with the categories or names we want to become their own column (REGION, so each region name is a new column)
- The values we want these new columns populated with (ITEMS)

The 2 parameters we need to specify are (conveniently) called *names_from* and *values_from*.

```{r}
data %>% 
  group_by(YEAR, REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = REGION, values_from = ITEMS)
```

As we can see, we now have a table that is more readable and could be included within a report.
Tables in the 'tall format' are required for visualisation functions (like hchart) and not formatted to be readable.

## Renaming Columns

Finally, we can easily rename columns using the *rename* function. If you want your column name to have a space between multiple words you need to wrap the column name in tick marks like this *`My Column Name`*. Remember, we would need to specify the column name in tick marks if you were to use it within a different function as well.

```{r}
data %>% 
  group_by(YEAR, REGION) %>% 
  summarise(ITEMS = sum(ITEMS)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = REGION, values_from = ITEMS) %>% 
  rename(
    Year = YEAR,
    `East of England` = `EAST OF ENGLAND`
  )
```

## Summary

We now have an introduction to dplyr, how to pipe functions, and how to do some basic data transformations and aggregations.
Below is a list of the functions introduced in this section:

- install.packages()
- library()
- select()
- filter()
- distinct()
- group_by()
- summarise()
- ungroup()
- sum()
- n_distinct()
- arrange()
- top_n()
- pivot_wider()

## Exercise

Now try the exercise within the Transforming and Aggregating Data folder.
This is found within the 'transforming_and_aggregating_data_exercise.r' script.
This is a 'regular' R script rather than a markdown document.
Write your code to answer each question within the script.
